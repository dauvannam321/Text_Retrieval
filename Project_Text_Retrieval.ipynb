{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dauvannam321/Text_Retrieval/blob/main/Project_Text_Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup"
      ],
      "metadata": {
        "id": "qlS1zmFZ2Gjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and read corpus"
      ],
      "metadata": {
        "id": "x62qdTKS9DCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output"
      ],
      "metadata": {
        "id": "7J7c0huhafWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# link: https://drive.google.com/file/d/1ydGNBdRVloX9rtxsKrMSnUNFG43Qv1sl/view?usp=sharing\n",
        "!gdown --id 1ydGNBdRVloX9rtxsKrMSnUNFG43Qv1sl\n",
        "!unzip news_corpus.zip\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "Rjn6gbXV9CWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define vectorize text function"
      ],
      "metadata": {
        "id": "E4TmYC6oFoGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download vietnamese stopwords: https://raw.githubusercontent.com/stopwords/vietnamese-stopwords/master/vietnamese-stopwords.txt\n",
        "!gdown --id 1W9zVRz--bHlbBXbCSmoWHBO_2Cs4EhPY\n",
        "!unzip vn_stopwords.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21LiNGAqoY0r",
        "outputId": "72538e38-436a-41f1-be78-93b1f315cb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1W9zVRz--bHlbBXbCSmoWHBO_2Cs4EhPY\n",
            "To: /content/vn_stopwords.zip\n",
            "100% 6.89k/6.89k [00:00<00:00, 12.3MB/s]\n",
            "Archive:  vn_stopwords.zip\n",
            "  inflating: vietnamese-stopwords.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def remove_punctuations(text: str) -> str:\n",
        "  return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "with open('vietnamese-stopwords.txt', 'r', encoding='utf8') as f:\n",
        "  vn_stopwords = f.readlines()\n",
        "def remove_stopwords(text: str) -> str:\n",
        "  new_text = text\n",
        "  for w in vn_stopwords:\n",
        "    if w in new_text:\n",
        "      new_text = new_text.replace(w, '')\n",
        "\n",
        "  return new_text\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "  normalized_text = text.lower()\n",
        "  normalized_text = remove_punctuations(normalized_text)\n",
        "  normalized_text = remove_stopwords(normalized_text)\n",
        "\n",
        "  return normalized_text"
      ],
      "metadata": {
        "id": "v-O_-9xCGVtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create vectorize function using bag-of-words on a provided vocab"
      ],
      "metadata": {
        "id": "cuJVtq3eYbEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(text: str, vocab: list) -> np.ndarray:\n",
        "  normalized_text = normalize_text(text)\n",
        "  vec = []\n",
        "  for word in vocab:\n",
        "    vec.append(normalized_text.count(word))\n",
        "  return np.array(vec)"
      ],
      "metadata": {
        "id": "q4J5KyuNYeoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Building document-term matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "jNV1g8DTzLM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Create vocab"
      ],
      "metadata": {
        "id": "k6Y6h6VbYCr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_lists = []\n",
        "vocab = []\n",
        "dataset_root_path = 'news_corpus'\n",
        "filenames = os.listdir(dataset_root_path)\n",
        "for i in tqdm(range(len(filenames) // 20)):\n",
        "  filename = filenames[i]\n",
        "  filepath = os.path.join(dataset_root_path, filename)\n",
        "  with open(filepath, 'r', encoding='utf8') as f:\n",
        "    lines = f.readlines()\n",
        "    title = lines[0].strip()\n",
        "    article = ' '.join(lines[1:]).strip()\n",
        "    article = normalize_text(article)\n",
        "    if (title, article) not in doc_lists:\n",
        "      doc_lists.append((title, article))\n",
        "    tokens = article.split(' ')\n",
        "    for token in tokens:\n",
        "      if token not in vocab:\n",
        "        vocab.append(token)"
      ],
      "metadata": {
        "id": "cdTVWBlTTrB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d422439-ebe5-4b1e-a679-5c207662475b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9226/9226 [02:54<00:00, 52.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Create document-term matrix"
      ],
      "metadata": {
        "id": "iFJEDc-Mp8Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "term_document_matrix = {}\n",
        "for (title, article) in tqdm(doc_lists):\n",
        "  vec = vectorize(article, vocab)\n",
        "  term_document_matrix[(title, article)] = vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehkhHfahYU56",
        "outputId": "3010b058-4a48-4f06-c1e8-d99b816149ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9224/9224 [16:52<00:00,  9.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Ranking"
      ],
      "metadata": {
        "id": "z1OXdx2KL2D7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create similiarity measurement function (l1/l2 norm, cosine similarity)"
      ],
      "metadata": {
        "id": "1CXZUi10HpVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distance(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
        "  numerator = np.dot(a,b)\n",
        "  denominator = np.linalg.norm(a) * np.linalg.norm(b)\n",
        "\n",
        "  return numerator / denominator"
      ],
      "metadata": {
        "id": "Gsu29WVBHsnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create ranking function that will calculate similarity between query and each document then sort the results"
      ],
      "metadata": {
        "id": "Ob6jdozbwfEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ranking(query: str, term_document_matrix: dict, print_top_10: bool = True) -> list:\n",
        "  query_vec = vectorize(normalize_text(query), vocab=vocab)\n",
        "  rankings = []\n",
        "  for doc_info, vec in tqdm(term_document_matrix.items()):\n",
        "    score = distance(query_vec,vec)\n",
        "    rankings.append([score,(doc_info[0])])\n",
        "  rankings.sort(reverse=True)\n",
        "  print(\"\\n\")\n",
        "  if print_top_10 == True:\n",
        "    for rank in rankings[:10]:\n",
        "      print(rank)\n",
        "\n",
        "  return rankings"
      ],
      "metadata": {
        "id": "u_L-rw2rbT_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"điểm thi đại học\"\n",
        "rankings = ranking(query, term_document_matrix, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Muo2FftxdowY",
        "outputId": "9ce30556-1e89-4088-efd8-bd6ab7d4037f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9224/9224 [00:04<00:00, 1960.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[0.9736109723711444, \"Tổ hợp KHXH: Lịch sử 'thăng hạng' với gần 1.800 bài thi đạt điểm 10\"]\n",
            "[0.970495805386389, 'Công bố điểm thi tốt nghiệp THPT 2022 chính thức']\n",
            "[0.9703662987772426, 'Hà Nội, TPHCM dẫn đầu cả nước về số điểm 10 môn Toán thi tốt nghiệp 2022 | Báo Dân trí']\n",
            "[0.9703002725671075, 'Điểm sàn Đại học Quốc gia Hà Nội 2022 bao nhiêu?']\n",
            "[0.9701758322120065, 'Thí sinh mắc Covid-19 từ chối đặc cách | Báo Dân trí']\n",
            "[0.9698769246600187, 'Đạt 28.7 điểm, thí sinh Hải Phòng, Hà Tĩnh là đồng thủ khoa khối D1 | Báo Dân trí']\n",
            "[0.9693740750397898, 'Thi tốt nghiệp THPT 2022: Điểm học bạ cao hơn điểm thi']\n",
            "[0.9692245104202254, 'Thi tốt nghiệp THPT 2022: Cách tính điểm có gì đặc biệt?']\n",
            "[0.9691823487923342, 'Nam sinh Bắc Giang là thủ khoa kỳ thi đánh giá tư duy Đại học Bách khoa Hà Nội']\n",
            "[0.9689996694430342, 'Xuất hiện điểm tuyệt đối tại kỳ thi tuyển sinh lớp 10 ở TP.HCM']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZfBnGdtElJTXtK6UPb9s6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}